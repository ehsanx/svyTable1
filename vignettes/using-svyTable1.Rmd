---
title: "Creating Publication-Ready Tables with svyTable1"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating Publication-Ready Tables with svyTable1}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
link-citations: yes
---

```{r setup}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The **svyTable1** package provides a suite of functions for creating publication-ready tables from complex analytical results. Its capabilities are divided into two main areas:

1.  **Complex Survey Analysis:** Generating descriptive "Table 1" summaries (`svytable1()`), regression diagnostics (`svydiag()`), goodness-of-fit tests (`svygof()`), design-correct AUCs (`svyAUC()`) and analyzing interaction effects (`addint`, `addintlist`, `jointeffects`, `inteffects`, `reportint` from **survey** package objects.
2.  **Multiple Imputation Results:** Formatting pooled regression model outputs (`svypooled()`) from **mice** package objects into clean, "fallacy-safe" tables.

This vignette demonstrates how to use these functions to produce transparent and reliable tables for your research.

## Describing Complex Survey Data

The `svytable1` function defaults to `mode = "mixed"`. This approach is considered a best practice in high-quality survey research for several key reasons rooted in transparency.

When you present a table in mixed mode, you provide two types of information for each categorical variable:

- **The Unweighted N:** This is the actual number of people you interviewed in that category. It tells the reader about the statistical precision of the estimate [@seidenberg2023preferred]. A percentage based on 10 people is much less reliable than one based on 1,000 people.
- **The Weighted Percentage (%):** This is an estimate of the proportion of the entire target population that falls into that category, adjusted for the complex survey design (e.g., oversampling of certain groups) [@national1994plan].

By showing both, you allow your audience to understand the crucial distinction between your sample and the population you are making inferences about. It also reveals the impact of the survey weights—if a group has a small N but a large weighted percentage, it signals that the estimate for that group relies heavily on up-weighting a few individuals, which may affect the stability of the estimate.

## Example: Using NHANES Data (2009–2012)

### 1. Data Preparation

```{r tab}
library(svyTable1)
library(survey)
library(dplyr)
library(NHANES)
library(knitr)

# Load the raw NHANES data (2009-2012)
data(NHANESraw)

# Prepare data for adults, keeping NAs
nhanes_adults_with_na <- NHANESraw %>%
  dplyr::filter(Age >= 20) %>%
  mutate(
    ObeseStatus = factor(ifelse(BMI >= 30, "Obese", "Not Obese"),
                         levels = c("Not Obese", "Obese"))
  )

# Create the survey design object on the data that still contains NAs
adult_design_with_na <- svydesign(
  id = ~SDMVPSU,
  strata = ~SDMVSTRA,
  weights = ~WTMEC2YR,
  nest = TRUE,
  data = nhanes_adults_with_na
)
```

### 2. Generating Tables

#### Example A: Handling Variables with Missing Data

```{r na}
# Define a set of variables, some with expected missing values
vars_with_missing <- c(
  "Age", 
  "Gender", 
  "Race1", 
  "Education",
  "HHIncome", 
  "TotChol",       
  "SleepHrsNight", 
  "SmokeNow"       
)

# Generate the table using the full design object (with NAs)
table_with_missing <- svytable1(
  design = adult_design_with_na, 
  strata_var = "ObeseStatus", 
  table_vars = vars_with_missing
)

# Display the table
knitr::kable(
  table_with_missing, 
  caption = "Table 1: Summarizing Variables with Missing Data"
)
```

It's important to note that `svytable1()` automatically detects missing (`NA`) values in the stratification variable. It treats these observations as a distinct group, creating a separate 'Missing' column in the table to ensure all data is accounted for.

#### Example B: Summarizing Complete Data

```{r compl}
library(tidyr)

# Define a set of core variables for a complete-case analysis
vars_for_complete_table <- c(
  "Age", 
  "Gender", 
  "Race1",
  "BPSysAve",
  "Pulse",
  "BMI"
)

# Create a new, complete-case data frame
nhanes_adults_complete <- nhanes_adults_with_na %>%
  drop_na(all_of(vars_for_complete_table))

# Create a new design object based on this complete-case data
adult_design_complete <- svydesign(
  id = ~SDMVPSU,
  strata = ~SDMVSTRA,
  weights = ~WTMEC2YR,
  nest = TRUE,
  data = nhanes_adults_complete
)

# Generate the table
table_without_missing <- svytable1(
  design = adult_design_complete, 
  strata_var = "ObeseStatus", 
  table_vars = c("Age", "Gender", "Race1", "BPSysAve", "Pulse")
)

# Display the table
knitr::kable(
  table_without_missing, 
  caption = "Table 2: Summarizing Variables with No Missing Data"
)
```

This table is "clean": it has no "Missing" rows or columns because the input data was complete for the selected variables.

## 3. Checking Estimate Reliability for Proportions (NCHS Standards)

When you publish research, it's crucial to ensure your results are statistically trustworthy. An estimate based on a very small number of people, for example, can be misleading. To help with this, `svytable1` can automatically apply the **NCHS Data Presentation Standards for Proportions**, which are a set of rules designed to prevent the publication of unreliable estimates.

You can activate this feature using two arguments:

- **`reliability_checks = TRUE`**: This tells the function to perform the checks. Any estimate that fails is replaced with an asterisk (*) in the final table.
- **`return_metrics = TRUE`**: This is highly recommended. It tells the function to return a second table—a detailed report card—that shows exactly why an estimate passed or failed.

### Example C: Generating a Table with Reliability Checks

Let's run our analysis again with the reliability checks turned on.

```{r rel}
# Generate the table and the reliability metrics
results_list <- svytable1(
  design = adult_design_with_na, 
  strata_var = "ObeseStatus", 
  table_vars = vars_with_missing,
  reliability_checks = TRUE,
  return_metrics = TRUE
)

# Display the formatted table with suppressed estimates
knitr::kable(
  results_list$formatted_table, 
  caption = "Table 3: Table with NCHS Reliability Checks Applied"
)
```

You'll notice asterisks (*) in the table. These are estimates that the function has flagged as unreliable based on the NCHS rules [@nhanes_reliability_estimates]. To see why, we can look at the metrics table.

```{r displ}
# Display the detailed reliability metrics
knitr::kable(
  results_list$reliability_metrics[results_list$reliability_metrics$suppressed == TRUE,], 
  caption = "Reliability metrics for those that are supressed"
)
# Check results_list$reliability_metrics for full list
```

## Interpreting the Reliability Metrics

The second table, `reliability_metrics`, is the "report card" for each estimate. The `suppressed` column gives the final verdict (`TRUE` or `FALSE`), and the `fail_...` columns tell you exactly which rule was broken.

Here’s what each check means in simple terms:

### `fail_n_30` (Sample Size Rule)

**What it is:** Checks if the actual number of people surveyed for a specific category (n) is at least 30.  
**Why it matters:** Estimates based on fewer than 30 individuals are too unstable to be reliable.

### `fail_eff_n_30` (Effective Sample Size Rule)

**What it is:** Adjusts for survey weights. The "effective" sample size is the equivalent simple random sample size with the same precision.  
**Rule:** If this effective sample size is less than 30, the estimate is flagged.

### `fail_df_8` (Degrees of Freedom Rule)

**What it is:** Measures how complex your survey design is.  
**Why it matters:** If the degrees of freedom are less than 8, the uncertainty estimate is unreliable.

### `fail_ciw_30` & `fail_rciw_130` (Confidence Interval Width Rules)

**What it is:** Evaluates the width of the confidence interval (CI) — the range of uncertainty around your estimate.  
**Why it matters:** Wide CIs indicate poor precision. These rules flag estimates with CIs too wide to be meaningful.

## 4. Checking Estimate Reliability for Means (NCHS Standards)

### fail_rse_30 (Relative Standard Error)

**What it is:**  
The *Relative Standard Error (RSE)* is a measure of an estimate's imprecision relative to its size, calculated as:

\[
RSE = \frac{Standard\ Error}{Estimate} \times 100
\]

An RSE of **30%** has historically been a common cutoff for determining if an estimate is unreliable.

---

**What it's useful for:**

- **Checking Reliability of Means:**  
  RSE is the *current recommended reliability check for means* [@nhanes_reliability_estimates].  
  According to the NCHS guideline, an estimated mean with an **RSE ≥ 30%** should be identified as unreliable.  
  The `svytable1` function automates this check for all numeric variables.

- **Historical Comparison:**  
  RSE allows comparison with older studies or agency standards that still apply the “RSE < 30%” rule for proportions.

- **General Diagnostic:**  
  It provides a quick, familiar *rule of thumb* to gauge the stability of an estimate, complementing the more modern NCHS checks for proportions.

## Extending Reliability Checks to Regression Models

While `svytable1()` focuses on descriptive statistics, a common next step in analysis is fitting a regression model. Assessing the reliability of regression coefficients is just as important as checking descriptive estimates. To support this workflow, the `svyTable1` package now includes `svydiag()`, a helper function for diagnosing the stability of coefficients from `svyglm()` models.

The function provides key metrics recommended for this purpose, such as the **p-value**, **standard error**, and **confidence interval width**. It also includes the Relative Standard Error (RSE) for comparison, though it is not the recommended primary check for regression coefficients due to its tendency to be misleading for estimates near zero.

### Example: Running Diagnostics on a Survey-Weighted Model

Let's fit a logistic regression model to predict obesity (`ObeseStatus`) using the complete-case NHANES data we prepared earlier. We'll then use `svydiag()` to assess the reliability of our model's coefficients.

```{r reg-diagnostics}
# 1. Fit a survey-weighted logistic regression model
# We use the 'adult_design_complete' object from Example B
fit_obesity <- svyglm(
  ObeseStatus ~ Age + Gender + Race1,
  design = adult_design_complete,
  family = quasibinomial()
)

# 2. Run the diagnostics function on the fitted model
diagnostics_table <- svydiag(fit_obesity)

# 3. Display the diagnostics table
knitr::kable(
  diagnostics_table,
  caption = "Reliability Diagnostics for NHANES Obesity Model",
  digits = 3
)
```

## Interpreting the Regression Diagnostics Table

The output from `svydiag()` provides a clear, term-by-term *report card* for your regression model. It helps you evaluate the reliability and interpretability of each coefficient.

### Key Columns

- **Estimate:**  
  The coefficient on the log-odds scale. It represents the change in the log-odds of the outcome per unit change in the predictor.

- **p.value** and **is_significant:**  
  These indicate whether a predictor has a statistically significant association with the outcome.  
  In our example, *Age* and *Race1 (Black)* are significant, while *Gender* is not.

- **CI_Width:**  
  This measures the precision of the estimate — smaller confidence interval widths imply more precise estimates.  
  For instance, the width for *GenderMale* is relatively narrow, but since its estimate is close to zero, it is not statistically significant.

- **RSE_percent** and **is_rse_high:**  
  These columns illustrate the limitation of using **Relative Standard Error (RSE)** in regression contexts.  
  The *GenderMale* coefficient shows a very high RSE (over 200%) because its estimate is near zero, even though its standard error is moderate.  
  This highlights why focusing on **p-values** and **confidence intervals** provides a more reliable assessment of coefficient stability than RSE alone.

---

Overall, `svydiag()` complements traditional regression output by making it easier to identify which predictors are both statistically meaningful and statistically stable under complex survey design.


## Goodness-of-Fit Test for Survey Models

The package also includes `svygof()` to perform the Archer-Lemeshow goodness-of-fit test. This test helps assess how well your logistic regression model fits the data. A non-significant p-value (e.g., > 0.05) suggests that the model is a good fit.

```{r gof-test}
# We use the same model and design from the regression diagnostics example
# 1. Run the goodness-of-fit test
gof_results <- svygof(fit_obesity, adult_design_complete)

# 2. Display the results
knitr::kable(
  gof_results,
  caption = "Archer-Lemeshow Goodness-of-Fit Test for Obesity Model"
)
```

This significant p-value suggests that there is evidence of a poor fit. The model does not accurately predict the outcomes across the different risk groups, indicating that it may be mis-specified or missing important variables or interactions.

## Design-Correct AUC for Model Performance

To evaluate the predictive performance of a model, you can calculate the Area Under the Curve (AUC) using `svyAUC()`. This function correctly accounts for the complex survey design (strata, clusters, and weights) by using a replicate-weights design object, which provides a more accurate estimate of the AUC's variance and confidence interval.

```{r auc-calculation}
# 1. The svyAUC() function requires a replicate-weights design object.
# We convert our existing design object for this purpose.
rep_design <- as.svrepdesign(adult_design_complete)

# 2. Refit the model using the (replicate) design object
fit_obesity_rep <- svyglm(
  ObeseStatus ~ Age + Gender + Race1,
  design = rep_design,
  family = quasibinomial()
)

# 3. Calculate the design-correct AUC
auc_results_list <- svyAUC(fit_obesity_rep, rep_design, plot = TRUE)

# 2. Display the summary table from the list
knitr::kable(
  auc_results_list$summary,
  caption = "Design-Correct AUC for Obesity Model"
)

# Use the roc_data component to build a custom ggplot
library(ggplot2)
ggplot(auc_results_list$roc_data, aes(x = FPR, y = TPR)) +
  geom_line(color = "blue", size = 1) +
  geom_abline(linetype = "dashed") +
  labs(
    title = "Survey-Weighted ROC Curve",
    subtitle = paste0("AUC = ", round(auc_results_list$summary$AUC, 3)),
    x = "1 - Specificity (FPR)",
    y = "Sensitivity (TPR)"
  ) +
  theme_minimal()
```

An AUC of 0.5 represents a model with no better-than-random chance of discriminating between outcomes. The model's AUC of 0.587 is very close to this baseline, which indicates poor to failed discrimination. It is not effective at distinguishing between individuals who are obese and those who are not.

---

## Formatting Results from Multiple Imputation

Beyond survey data, a common analytical challenge is presenting results from models fitted to multiply imputed datasets. The **svyTable1** package provides the `svypooled()` function to address this. It takes a pooled model object (`mipo`) from the `mice` package and creates a publication-ready table of regression coefficients (e.g., Odds Ratios).

A key feature of `svypooled()` is its ability to create a **"fallacy-safe"** table. This best-practice approach displays results for the main exposure variable only, while listing all adjustment covariates in a footnote. This prevents the common misinterpretation of covariate p-values as if they were main effects in their own right.

### Example: Handling Missing Data in a Survey Design

When you have missing data in a complex survey, the correct approach is to first perform multiple imputation on the raw dataset and then run your survey-weighted model on each of the completed datasets. The results are then pooled, and this final pooled object is what you format with `svypooled()`.

#### Data Preparation

First, we'll prepare the raw `NHANESraw` data.

```{r mice}
# Load required packages
library(mice)
library(dplyr)
library(survey)
library(NHANES)

data(NHANESraw, package = "NHANES")
nhanes_analytic <- NHANESraw %>%
  filter(Age >= 20 & WTMEC2YR > 0) %>% 
  mutate(
    Obese = factor(ifelse(BMI >= 30, "Yes", "No"), levels = c("No", "Yes")),
    AgeCat = cut(Age, breaks = c(19, 39, 59, 80), labels = c("20-39", "40-59", "60-80")),
    Smoke100 = factor(Smoke100, levels = c("No", "Yes"))
  ) %>%
  select(Obese, AgeCat, Smoke100, Education, SDMVPSU, SDMVSTRA, WTMEC2YR)
```

#### Pooling from Imputed Data

```{r mice-fit}
imputed_data <- mice(nhanes_analytic, m = 2, maxit = 2, seed = 123, printFlag = FALSE)
fit_list <- list()
for (i in 1:imputed_data$m) {
  completed_data <- complete(imputed_data, i)
  design_i <- svydesign(id = ~SDMVPSU, strata = ~SDMVSTRA, weights = ~WTMEC2YR, nest = TRUE, data = completed_data)
  fit_list[[i]] <- svyglm(Obese ~ Smoke100 + AgeCat + Education, design = design_i, family = quasibinomial())
}
pooled_results <- pool(fit_list)
```

#### Generating the Table with `svypooled`

```{r mice-pool}
# Example A: Create a "fallacy-safe" table (default)
svypooled(
 pooled_model = pooled_results,
 main_exposure = "Smoke100", 
 adj_var_names = c("AgeCat", "Education"),
 measure = "OR",
 title = "Adjusted Odds of Obesity (Fallacy-Safe)"
)


# Example B: Create a full table with all variables
svypooled(
 pooled_model = pooled_results,
 main_exposure = "Smoke100", 
 adj_var_names = c("AgeCat", "Education"),
 measure = "OR",
 title = "Adjusted Odds of Obesity (Full Table for Appendix)",
 fallacy_safe = FALSE
)
```


---

## Analyzing Interaction Effects

The `svyTable1` package includes several functions to help analyze and present interaction effects between two categorical variables in survey-weighted regression models (`svyglm` or `svycoxph`). These functions facilitate demonstrating the equivalence of different modeling approaches (joint variable vs. interaction term) and calculating measures of additive interaction.

### Example: Interaction between Race and Obesity on Hypertension (NHANES)

We will use the NHANES data to investigate whether the effect of obesity (`ObeseStatus`) on hypertension (Hypertension_130, defined as Systolic BP >= 130 mmHg) differs across racial groups (`Race1`).

## 1. Data Preparation and Model Fitting

```{r interaction-setup}}
data(NHANESraw)

vars_needed <- c("Age", "Race1", "BPSysAve", "BMI", "ObeseStatus", "Hypertension_130",
                 "SDMVPSU", "SDMVSTRA", "WTMEC2YR")

nhanes_adults_processed <- NHANESraw %>%
  filter(Age >= 20) %>%
  mutate(
    ObeseStatus = factor(ifelse(BMI >= 30, "Obese", "Not Obese"),
                         levels = c("Not Obese", "Obese")),
    Hypertension_130 = factor(ifelse(BPSysAve >= 130, "Yes", "No"),
                              levels = c("No", "Yes")),
    Race1 = relevel(as.factor(Race1), ref = "White")
  ) %>%
  select(all_of(vars_needed)) %>%
  drop_na()

adult_design_binary <- svydesign(
  id = ~SDMVPSU,
  strata = ~SDMVSTRA,
  weights = ~WTMEC2YR,
  nest = TRUE,
  data = nhanes_adults_processed
)

interaction_model_logit <- svyglm(
  Hypertension_130 ~ Race1 * ObeseStatus + Age,
  design = adult_design_binary,
  family = quasibinomial()
)

adult_design_binary <- update(adult_design_binary,
  Race1_ObeseStatus = interaction(Race1, ObeseStatus, sep = "_", drop = TRUE)
)
adult_design_binary <- update(adult_design_binary,
  Race1_ObeseStatus = relevel(Race1_ObeseStatus, ref = "White_Not Obese")
)
joint_model_logit <- svyglm(
  Hypertension_130 ~ Race1_ObeseStatus + Age,
  design = adult_design_binary,
  family = quasibinomial()
)

f1_levels <- levels(adult_design_binary$variables$Race1)
f2_levels <- levels(adult_design_binary$variables$ObeseStatus)
```

## 2. Additive Interaction Measures

This section calculates measures of **additive interaction**. The `addintlist()` function
automatically finds every combination of non-reference levels for your two factors (`Race1` and
`ObeseStatus`) and computes three key metrics for each 2x2 comparison [@knol2012recommendations].

• **RERI (Relative Excess Risk due to Interaction)**: Measures the excess risk from the
  interaction itself, relative to the baseline risk. A value of 0 means no additive interaction.

• **AP (Attributable Proportion due to Interaction)**: Estimates the fraction of the risk among
  those with *both* risk factors that is attributable to their interaction. A value of 0 means no
  additive interaction.

• **S (Synergy Index)**: Assesses whether the effect of both factors together is greater than
  (synergistic, S > 1) or less than (antagonistic, S < 1) the sum of their individual effects.
  A value of 1 means no additive interaction.

The table shows these metrics for each comparison (e.g., `"Race1: Black"` vs. `"ObeseStatus: Obese"`).
For the first row, the RERI is 0.025 with a 95% CI of [-0.587, 0.637]. Since this interval clearly
contains 0, **there is no evidence of an additive interaction** between `'Race1: Black'` and
`'ObeseStatus: Obese'` on the risk of hypertension.


```{r all-interactions}
all_interactions_table <- addintlist(
  model = interaction_model_logit,
  factor1_name = "Race1",
  factor2_name = "ObeseStatus",
  measures = "all",
  digits = 3
)
knitr::kable(all_interactions_table,
  caption = "Additive Interaction Measures (RERI, AP, S) for Race x Obesity on Hypertension",
  digits = 3)
```

## 3. Joint Effects

This section estimates the **joint effects** for every combination of `Race1` and `ObeseStatus`,
all relative to the single reference group (`White`, `Not Obese`).

The `jointeffects()` function uses the coefficients from your **interaction model**
(`~ Race1 * ObeseStatus`) to mathematically combine the main effects and interaction terms.

For example, the effect for `Black` + `Obese` is calculated by summing the model coefficients:

`log(OR) = (effect of Black) + (effect of Obese) + (effect of Black:Obese interaction)`

This provides a single, easy-to-interpret **odds ratio (OR)** for each group compared to the reference group.

• **Ratio Scale Table**: Shows the final ORs. The `'Black' + 'Obese'` group has an OR of 2.53
  (95% CI: 1.98–3.24) for hypertension compared to the `'White' + 'Not Obese'` group.
  The reference group (`White`, `Not Obese`) is correctly shown as **1.00**.

• **Log Scale Table**: Shows the same information on the **log-odds scale**, which the model uses internally.
  For example, `exp(0.930)` from the log table equals **2.53** from the ratio table.


```{r joint-effects}
joint_effects_ratio <- jointeffects(
  interaction_model = interaction_model_logit,
  factor1_name = "Race1",
  factor2_name = "ObeseStatus",
  scale = "ratio",
  digits = 2)
knitr::kable(joint_effects_ratio,
  caption = "Joint Effects (OR Scale) Estimated from Interaction Model",
  digits = 2)

joint_effects_log <- jointeffects(
  interaction_model = interaction_model_logit,
  factor1_name = "Race1",
  factor2_name = "ObeseStatus",
  scale = "log",
  digits = 3)
knitr::kable(joint_effects_log,
  caption = "Joint Effects (Log-OR Scale) Estimated from Interaction Model",
  digits = 3)
```

## 4. Simple Effects

This section calculates the **simple effects**, which are stratum-specific comparisons. This is the
classic way to present an interaction, as it shows how the effect of one variable **changes** across
the levels of another.

The `inteffects()` function is designed to work on a **joint-variable model** (one fit with a
combined `Race1_ObeseStatus` variable). It uses the estimates from that model to calculate all
the pairwise comparisons **within** specific strata.

The table is broken into two parts:

1. **Effect of Obesity, stratified by Race**:  
   The first five rows (e.g., `ObeseStatus(Obese vs Not Obese): Race1(White)`) show the effect of
   being obese **within** each racial group. You can see the OR for obesity is **1.40** for the
   'White' group, but **1.20** for the 'Black' group, **1.66** for 'Hispanic', etc.
   This variation *is* the interaction.

2. **Effect of Race, stratified by Obesity**:  
   The remaining rows (e.g., `Race1(Black vs White): ObeseStatus(Not Obese)`) show the effect of
   race/ethnicity **within** each obesity status group.  
   For example, the OR for 'Black vs White' is **2.11** among 'Not Obese' individuals, but only
   **1.81** among 'Obese' individuals.

The **p-value** column tells you if that specific simple effect is statistically significant.


```{r simple-effects}
simple_effects_ratio <- inteffects(
  joint_model = joint_model_logit,
  joint_var_name = "Race1_ObeseStatus",
  factor1_name = "Race1",
  factor2_name = "ObeseStatus",
  factor1_levels = f1_levels,
  factor2_levels = f2_levels,
  level_separator = "_",
  scale = "ratio",
  digits = 2)
knitr::kable(simple_effects_ratio,
  caption = "Simple Effects (OR Scale) Estimated from Joint Model",
  digits = 2)

simple_effects_log <- inteffects(
  joint_model = joint_model_logit,
  joint_var_name = "Race1_ObeseStatus",
  factor1_name = "Race1",
  factor2_name = "ObeseStatus",
  factor1_levels = f1_levels,
  factor2_levels = f2_levels,
  level_separator = "_",
  scale = "log",
  digits = 3)
knitr::kable(simple_effects_log,
  caption = "Simple Effects (Log-OR Scale) Estimated from Joint Model",
  digits = 3)
```

## 5. Automated Multi-Panel Report

The `reportint()` function is the recommended high-level wrapper for interaction analysis. It takes the single fitted interaction model (`interaction_model_logit`) and automatically generates all required components for a full analysis.

The function returns a list containing two types of objects:

- **Raw Data Panels:** Separate tables for `joint_effects`, `stratum_specific_effects`, `additive_interaction`, `multiplicative_scale`, and `model_details` for custom analysis.

- **Publication-Ready Tables:** Two pre-formatted, single, stacked tables (`$effect_modification_report` and `$Interaction_report`) that assemble the raw data according to the reporting guidelines.

The main list output is ideal for vignettes, while `output = "viewer"` renders a full HTML report. Below, we demonstrate the new single-table outputs.

```{r reportint-wrapper, fig.cap="Figure 2: Example of reportint() HTML output."}
# Generate the complete report in one call
# We'll ask for the "list" output to use in the vignette
# For interactive use, try output = "viewer"
interaction_report <- reportint(
  interaction_model = interaction_model_logit,
  output = "list"
)

# Display the tables generated by the single function call
knitr::kable(
  interaction_report$joint_effects,
  caption = "Panel A (Joint Effects) from reportint()"
)

knitr::kable(
  interaction_report$stratum_specific_effects,
  caption = "Panel B (Simple Effects) from reportint()"
)

knitr::kable(
  interaction_report$additive_interaction,
  caption = "Panel C (Additive Interaction) from reportint()"
)

knitr::kable(
  interaction_report$model_details,
  caption = "Panel D (Model Details) from reportint()"
)

knitr::kable(
  interaction_report$multiplicative_scale,
  caption = "Multiplicative Interaction (RORs) from reportint()"
)

# Display the single, publication-ready table for Effect Modification
knitr::kable(
  interaction_report$effect_modification_report,
  caption = "Publication Report: Effect Modification Analysis (from reportint())",
  # Left-align columns to handle empty cells in stacked table
  align = 'l' 
)

# Display the single, publication-ready table for a Full Interaction
knitr::kable(
  interaction_report$Interaction_report,
  caption = "Publication Report: Full Interaction Analysis (from reportint())",
  # Left-align columns
  align = 'l' 
)
```

## 6. Visualizing Survey-Weighted Survival Data

A common task in health research is visualizing time-to-event data. The `svykmplot()` function is designed to create publication-ready, survey-weighted Kaplan-Meier survival plots, complete with an attached "Number at Risk" table that correctly reflects the unweighted counts at specific time points.

### Example: Plotting Survival from NHANES Mortality Data

This example uses the `nhanes_mortality` dataset, which is included in the `svyTable1` package. This dataset is based on [the 1999-2010 NHANES data linked to mortality follow-up data](https://ehsanx.github.io/EpiMethods/nonbinary2a.html). We will plot survival for diabetic women, stratified by caffeine consumption.

```{r km-plot, fig.width=8, fig.height=6, fig.cap="Survey-weighted Kaplan-Meier plot for female mortality by caffeine consumption."}
# 1. Load the package's built-in mortality data
# (This data is already processed, as shown in the package documentation)
data(nhanes_mortality)

# 2. Create the main survey design object
analytic_design <- svydesign(
  strata = ~strata,
  id = ~psu,
  weights = ~survey_weight,
  data = nhanes_mortality,
  nest = TRUE
)

# 3. Create a subsetted design for females
design_female <- subset(analytic_design, sex == "Female")

# 4. Define the formula
# We need the survival package for this
library(survival)
km_formula <- Surv(stime, status) ~ caff

# 5. Define a 4-color palette
distinct_palette <- c("#377EB8", "#FF7F00", "#4DAF4A", "#E41A1C")

# 6. Run the function
km_results_female <- svykmplot(
  formula = km_formula,
  design = design_female,
  legend_title = "Caffeine Consumption",
  time_unit = "days", 
  time_breaks = seq(0, 240, by = 60),
  palette = distinct_palette,
  show_pval = TRUE,
  show_censor_marks = TRUE
)

km_results_female$plot
```

The function returns a list, with the `plot` object being the combined `ggplot` and the `table` object being a clean data frame of the number-at-risk counts.

```{r kmtable}
# You can also print the number-at-risk table directly
knitr::kable(
  km_results_female$table,
  caption = "Number at Risk for Female Mortality Plot"
)
```


## References
